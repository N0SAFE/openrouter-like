---
title: Error Handling
description: Understanding and handling errors in the OpenRouter API
---

# Error Handling

This guide explains the error responses returned by the OpenRouter API and how to handle them in your applications.

## Error Response Format

When an API request fails, OpenRouter returns a JSON response with error details:

```json
{
  "error": {
    "message": "A human-readable error message",
    "type": "error_type",
    "param": "parameter_name",
    "code": 400
  }
}
```

| Field | Description |
|-------|-------------|
| `message` | A human-readable description of the error |
| `type` | The category of error (e.g., `invalid_request_error`) |
| `param` | The parameter that caused the error (if applicable) |
| `code` | The HTTP status code |

## Common Error Types

### Authentication Errors

| Status Code | Type | Description |
|-------------|------|-------------|
| 401 | `authentication_error` | Missing API key or invalid authentication |
| 403 | `permission_denied` | Valid API key but insufficient permissions |

### Request Errors

| Status Code | Type | Description |
|-------------|------|-------------|
| 400 | `invalid_request_error` | Malformed request (e.g., invalid JSON) |
| 400 | `validation_error` | Request validation failed (e.g., missing required fields) |
| 404 | `not_found` | Requested resource (model, etc.) not found |
| 429 | `rate_limit_exceeded` | Too many requests, exceeding your rate limit |

### Model Errors

| Status Code | Type | Description |
|-------------|------|-------------|
| 404 | `model_not_found` | The requested model does not exist |
| 503 | `model_overloaded` | The model is currently overloaded |
| 500 | `model_error` | Error while processing with the model |

### Internal Errors

| Status Code | Type | Description |
|-------------|------|-------------|
| 500 | `server_error` | Internal server error |
| 503 | `service_unavailable` | Service is temporarily unavailable |

## Error Handling Best Practices

### Retry with Backoff

For rate limits and temporary service issues:

```javascript
async function fetchWithRetry(url, options, maxRetries = 3) {
  let retries = 0;
  
  while (retries < maxRetries) {
    try {
      const response = await fetch(url, options);
      
      if (response.status === 429) {
        // Rate limited, get retry-after header or use exponential backoff
        const retryAfter = parseInt(response.headers.get('retry-after') || '1');
        await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
        retries++;
        continue;
      }
      
      if (response.status >= 500) {
        // Server error, use exponential backoff
        await new Promise(resolve => setTimeout(resolve, Math.pow(2, retries) * 1000));
        retries++;
        continue;
      }
      
      return response;
    } catch (error) {
      if (retries >= maxRetries - 1) throw error;
      await new Promise(resolve => setTimeout(resolve, Math.pow(2, retries) * 1000));
      retries++;
    }
  }
}
```

### Model Fallbacks

When a model is unavailable, try fallback models:

```javascript
async function generateWithFallbacks(prompt, models = ['anthropic/claude-3-opus', 'openai/gpt-4o', 'openai/gpt-3.5-turbo']) {
  for (const model of models) {
    try {
      const response = await fetch('https://api.openrouter.ai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model,
          messages: [{ role: 'user', content: prompt }]
        })
      });
      
      if (response.ok) {
        return await response.json();
      }
      
      // Only try next model if this one is unavailable (not for auth/validation errors)
      const error = await response.json();
      if (error.error.code !== 404 && error.error.code !== 503) {
        throw error;
      }
    } catch (error) {
      console.error(`Error with model ${model}:`, error);
      // Continue to next model
    }
  }
  
  throw new Error('All models failed');
}
```

### Handling Validation Errors

Check for validation errors and provide user-friendly messages:

```javascript
async function handleAPIRequest(url, options) {
  try {
    const response = await fetch(url, options);
    
    if (!response.ok) {
      const error = await response.json();
      
      if (error.error.type === 'validation_error') {
        return { success: false, message: `Please check your input: ${error.error.message}` };
      }
      
      if (error.error.type === 'authentication_error') {
        return { success: false, message: 'Authentication failed. Please check your API key.' };
      }
      
      return { success: false, message: `Error: ${error.error.message}` };
    }
    
    const data = await response.json();
    return { success: true, data };
  } catch (error) {
    return { success: false, message: 'An unexpected error occurred. Please try again.' };
  }
}
```

## Monitoring and Logging

Keep track of errors for better debugging and service quality:

1. **Log error details** (excluding sensitive information)
2. **Monitor error rates** for early detection of issues
3. **Track model performance** across different providers
4. **Analyze patterns** to optimize your API usage

## Next Steps

- [Chat Completion API](/docs/api/chat-completion)
- [Models API](/docs/api/models)
- [Fallbacks & Routing Guide](/docs/guides/fallbacks-routing)

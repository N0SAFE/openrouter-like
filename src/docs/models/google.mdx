---
title: Google Models
description: Guide to Google's Gemini models available through OpenRouter
---

# Google Gemini Models

OpenRouter provides access to Google's advanced Gemini AI models, which offer powerful reasoning capabilities, multi-modal understanding, and large context processing. This guide details the Google models available through OpenRouter.

## Available Google Models

| Model ID | Description | Context Window | Strengths |
|----------|-------------|----------------|-----------|
| `google/gemini-1.5-pro` | Google's most capable model | 1,000,000 tokens | Extremely large context, multimodal |
| `google/gemini-1.5-flash` | Fast, efficient model | 1,000,000 tokens | Speed, cost-efficiency, large context |
| `google/gemini-1.0-pro` | Previous generation model | 32,768 tokens | Reliability, reasoning |

## Gemini 1.5 Pro

Gemini 1.5 Pro is Google's flagship model, featuring an unprecedented 1 million token context window and strong multimodal capabilities.

### Key Features

- **Massive context window** - Process up to 1 million tokens (approximately 700,000 words)
- **Multimodal understanding** - Can process both text and images
- **Advanced reasoning** - Strong performance on complex reasoning tasks
- **Long-form understanding** - Can analyze entire books, codebases, or datasets

### Example Request

```javascript
const response = await fetch('https://api.openrouter.ai/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'google/gemini-1.5-pro',
    messages: [
      {role: 'user', content: 'Summarize the key technological trends that might emerge in the next decade.'}
    ],
    temperature: 0.7,
    max_tokens: 1000
  })
});
```

### Best Use Cases

- Document analysis and summarization
- Code repository understanding
- Research synthesis across multiple papers
- Complex data analysis
- Long conversational contexts

## Gemini 1.5 Flash

Gemini 1.5 Flash is Google's efficiency-focused model that balances speed, cost, and quality while maintaining the massive context window.

### Key Features

- **Low latency** - Faster response times than Gemini 1.5 Pro
- **Cost efficiency** - More economical for high-volume applications
- **Large context window** - Retains the 1 million token context
- **Balanced performance** - Good quality-to-cost ratio

### Best Use Cases

- Real-time applications requiring large contexts
- Cost-sensitive applications
- Content generation and summarization
- Educational applications
- Customer support with deep context

## Multimodal Capabilities

Gemini models support multimodal inputs, allowing for image analysis alongside text:

```javascript
// Note: Image data must be base64 encoded
const response = await fetch('https://api.openrouter.ai/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'google/gemini-1.5-pro',
    messages: [
      {
        role: 'user', 
        content: [
          {
            type: 'text',
            text: 'What's in this image?'
          },
          {
            type: 'image_url',
            image_url: {
              url: 'data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/4gxYSUNDX1BST0ZJTEUAAQEAAAxITGlu...'
            }
          }
        ]
      }
    ]
  })
});
```

## Safety Settings

Google models support safety settings to control content filtering:

```javascript
const response = await fetch('https://api.openrouter.ai/v1/chat/completions', {
  method: 'POST',
  headers: {
    'Authorization': `Bearer ${OPENROUTER_API_KEY}`,
    'Content-Type': 'application/json'
  },
  body: JSON.stringify({
    model: 'google/gemini-1.5-pro',
    messages: [
      {role: 'user', content: 'Write a creative story about space exploration.'}
    ],
    temperature: 0.7,
    google_safety_settings: [
      {
        category: "HARM_CATEGORY_DANGEROUS",
        threshold: "BLOCK_ONLY_HIGH"
      }
    ]
  })
});
```

## Generation Config

Gemini models support additional generation configuration parameters:

| Parameter | Description | Valid Range | Default |
|-----------|-------------|------------|---------|
| temperature | Controls randomness | 0-1 | 0.7 |
| max_tokens | Maximum tokens to generate | 1-8192 | Varies by model |
| top_p | Nucleus sampling parameter | 0-1 | 0.95 |
| top_k | Limits token selection | 1-40 | 40 |

## Pricing

| Model | Input (per 1M tokens) | Output (per 1M tokens) |
|-------|------------------------|------------------------|
| Gemini 1.5 Pro | $7.00 | $21.00 |
| Gemini 1.5 Flash | $1.50 | $5.00 |
| Gemini 1.0 Pro | $3.50 | $10.50 |

## Implementation Notes

- Google models may have slightly different parameter behavior than OpenAI or Anthropic models
- The massive context window is especially useful for applications dealing with large documents
- Consider using streaming for better user experience with large responses

## Next Steps

- [Explore OpenAI Models](/docs/models/openai)
- [Learn about Anthropic Models](/docs/models/anthropic)
- [Discover Open Source Models](/docs/models/open-source)
